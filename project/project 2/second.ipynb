{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6fc71b1b735d49a",
   "metadata": {},
   "source": [
    "## 1. Dataset overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6251e56d44c5b101",
   "metadata": {},
   "source": [
    "### 1.1 Brief overview of the [Amazon product review](https://github.com/rashakil-ds/Public-Datasets/blob/main/amazon.csv) dataset.\n",
    "\n",
    "#### The dataset contains the following columns:\n",
    "1. `reviewText`: The review text.\n",
    "2. `Positive`: The target variable. It is a binary variable indicating whether the review is positive or negative.\n",
    "\n",
    "#### The dataset contains 20000 rows and 2 columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f1dbb1a8294626",
   "metadata": {},
   "source": [
    "### 1.2 Describe columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462b70e3b947c42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('amazon.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b5fb3f13f5e797",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca0a6e832fa02b6",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8023c1ca43a0d11",
   "metadata": {},
   "source": [
    "### 2.1 Check for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168a47f6e27cf4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92c4145f5970c89",
   "metadata": {},
   "source": [
    "### 2.2 Perform text preprocessing (lowercasing, removing stop words, punctuation, etc.) on the `reviewText` column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f230c57a8c2cfd",
   "metadata": {},
   "source": [
    "#### 2.2.1 Lowercasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9c04ef6f996eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['reviewText'] = df['reviewText'].str.lower()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bdbdcde052302bc",
   "metadata": {},
   "source": [
    "#### 2.2.2 Remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a33ea59f3ca7f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    return ' '.join([word for word in text.split() if word not in stop_words])\n",
    "\n",
    "df['reviewText'] = df['reviewText'].apply(remove_stop_words)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6689a6160015",
   "metadata": {},
   "source": [
    "#### 2.2.3 Removing punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02316e16d6b93e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    return text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "df['reviewText'] = df['reviewText'].apply(remove_punctuation)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8a9566ddaac68c",
   "metadata": {},
   "source": [
    "#### 2.2.4 Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e779ab5f364d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2a2277e0a81ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize(text):\n",
    "    return ' '.join([lemmatizer.lemmatize(word) for word in text.split()])\n",
    "\n",
    "df['reviewText'] = df['reviewText'].apply(lemmatize)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bcd91560536b3e",
   "metadata": {},
   "source": [
    "#### 2.2.5 Diacritics removal aka accent removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1012a9333653b1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unidecode\n",
    "\n",
    "def remove_diacritics(text):\n",
    "    return unidecode.unidecode(text)\n",
    "\n",
    "df['reviewText'] = df['reviewText'].apply(remove_diacritics)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0a9dcca4ce4f67",
   "metadata": {},
   "source": [
    "#### 2.2.6 Expand contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb83527e4df6096",
   "metadata": {},
   "outputs": [],
   "source": [
    "import contractions\n",
    "\n",
    "def expand_contractions(text):\n",
    "    return contractions.fix(text)\n",
    "\n",
    "df['reviewText'] = df['reviewText'].apply(expand_contractions)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e455ad2489e4de89",
   "metadata": {},
   "source": [
    "### 2.3 Split the dataset into training and testing sets\n",
    "#### Using 80% of the data for training and 20% for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594c7392ec9ae46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df['reviewText']\n",
    "y = df['Positive']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4046de4fd2b09",
   "metadata": {},
   "source": [
    "## 3 Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835c1e95212864a5",
   "metadata": {},
   "source": [
    "### 3.1 Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4995a45827eae65",
   "metadata": {},
   "source": [
    "#### 3.1.1 Necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784a2ac15594e867",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a7ab8212759e7d",
   "metadata": {},
   "source": [
    "#### 3.1.2 Create a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dce45731615d014",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c9a4f281454c63",
   "metadata": {},
   "source": [
    "#### 3.1.3 Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9f43da6f5d4993",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285c4bcf5418a7b4",
   "metadata": {},
   "source": [
    "#### 3.1.4 Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f007c837e34e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e4941e6af6cae5",
   "metadata": {},
   "source": [
    "#### 3.1.5 Formal evaluation\n",
    "1. Accuracy\n",
    "2. Precision\n",
    "3. Recall\n",
    "4. F1-score\n",
    "5. Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8c8d1cd8c98606",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(f'Accuracy: {accuracy_score(y_test, y_pred)}')\n",
    "print('-'*60)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('-'*60)\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee300ef4a735a3c",
   "metadata": {},
   "source": [
    "## 3.1.6 Hyperparameter tuning using GridSearchCV\n",
    "### Why GridSearchCV?\n",
    "1. Small dataset\n",
    "2. Exhaustive search\n",
    "3. Few hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3b88a94c9becc4",
   "metadata": {},
   "source": [
    "#### 3.1.6.1 Necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e71fa4b6f274cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4f9fd752fe92e8",
   "metadata": {},
   "source": [
    "#### 3.1.6.2 Define hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac390103c646fd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'tfidf__max_df': [0.7, 0.8, 0.9],                     # Maximum document frequency\n",
    "    'tfidf__min_df': [1, 2, 5],                           # Minimum document frequency\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2)],               # N-gram range (unigrams, bigrams)\n",
    "    'tfidf__max_features': [5000, 10000],                 # Maximum number of features\n",
    "    'tfidf__use_idf': [True, False],                      # Whether to use IDF weighting\n",
    "    'clf__C': [0.01, 0.1, 1, 10],                        # Regularization strength\n",
    "    'clf__penalty': ['l2'],                              # Type of regularization (e.g., l2)\n",
    "    'clf__solver': ['liblinear'],                        # Solver algorithm\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42117fe5fede9621",
   "metadata": {},
   "source": [
    "#### 3.1.6.3 Fit the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e79e0df95b609cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(pipe, param_grid, cv=3, scoring='accuracy', verbose=2)\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfde4cc4c7f1443",
   "metadata": {},
   "source": [
    "#### 3.1.6.4 Best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4777825dae547703",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370ac92af7f49410",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a887a9e1b4447d72",
   "metadata": {},
   "source": [
    "### 3.2 Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b731ebb1c583b4b",
   "metadata": {},
   "source": [
    "#### 3.2.1 Necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce08f0161a304266",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f271f02c6e47a5b4",
   "metadata": {},
   "source": [
    "#### 3.2.2 Create a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bedf932590495a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "pipe_svm = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', SVC(verbose=True))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb1b384174f36",
   "metadata": {},
   "source": [
    "#### 3.2.3 Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c92a4d07e3c8fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0a73efcc87e96b",
   "metadata": {},
   "source": [
    "#### 3.2.4 Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53193235cbf54db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_svm = pipe_svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad370ef6ec332f9",
   "metadata": {},
   "source": [
    "#### 3.2.5 Formal evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176bb602696911f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Accuracy: {accuracy_score(y_test, y_pred_svm)}')\n",
    "print('-'*60)\n",
    "print(classification_report(y_test, y_pred_svm))\n",
    "print('-'*60)\n",
    "print(confusion_matrix(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fdd181afa76e6",
   "metadata": {},
   "source": [
    "#### 3.2.6 Hyperparameter tuning using GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8c34e9fd164e95",
   "metadata": {},
   "source": [
    "#### 3.2.6.1 Define hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fd8e1658ad16d8",
   "metadata": {},
   "source": [
    "### ⚠️ This takes a long time to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54118fb25a329f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'tfidf__max_df': [0.7, 0.8, 0.9],\n",
    "    'tfidf__min_df': [1, 2, 5],\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)],  # unigrams, bigrams, trigrams\n",
    "    'tfidf__max_features': [10000, 20000],  # Limit number of features\n",
    "    'tfidf__use_idf': [True, False],  # Use IDF weighting or not\n",
    "    'tfidf__sublinear_tf': [True, False],  # Apply sublinear scaling\n",
    "    \n",
    "    'clf__C': [0.1, 1, 10, 100],  # Regularization parameter\n",
    "    'clf__kernel': ['linear', 'rbf'],  # Kernel type\n",
    "    'clf__gamma': ['scale', 'auto', 0.01, 0.001],  # Kernel coefficient\n",
    "    'clf__class_weight': [None, 'balanced'],  # Handling class imbalance\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8ee1ba3357c497",
   "metadata": {},
   "source": [
    "### This is less exhaustive "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e05c195f398c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'tfidf__max_df': [0.8, 0.9],\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2)],  # Focus only on unigrams and bigrams\n",
    "    'clf__C': [1, 10],  # Start with fewer values for regularization\n",
    "    'clf__kernel': ['linear', 'rbf'],  # Stick to common kernels\n",
    "    'clf__gamma': ['scale', 'auto'],  # Reduce number of values for gamma\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10cc03d0063d804c",
   "metadata": {},
   "source": [
    "#### 3.2.6.2 Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92ce96b756666e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_svm = GridSearchCV(pipe_svm, param_grid, cv=3, scoring='accuracy', verbose=3)\n",
    "grid_svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988017ef06df69e5",
   "metadata": {},
   "source": [
    "### 3.3 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e6bf9367f48a1cd9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T12:17:06.026336Z",
     "start_time": "2024-09-30T12:16:59.841661Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.86525\n",
      "------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.52      0.65       958\n",
      "           1       0.87      0.97      0.92      3042\n",
      "\n",
      "    accuracy                           0.87      4000\n",
      "   macro avg       0.86      0.75      0.78      4000\n",
      "weighted avg       0.87      0.87      0.85      4000\n",
      "\n",
      "------------------------------------------------------------\n",
      "[[ 498  460]\n",
      " [  79 2963]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "pipe_rf = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "pipe_rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = pipe_rf.predict(X_test)\n",
    "\n",
    "print(f'Accuracy: {accuracy_score(y_test, y_pred_rf)}')\n",
    "print('-'*60)\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "print('-'*60)\n",
    "print(confusion_matrix(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e416b0df007525",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
